{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "As we saw in the previous chapter, we can explain to the machine which words are similar but also how different there are.\n",
    "\n",
    "However some \"different\" words are only variations of the same word and should not be considered as different entries. \n",
    "\n",
    "Let's take an example:\n",
    "\n",
    "Imagine that you are asked to build a model to classify books in two categories: _cooking_ and _cars_. You will use the most frequent words of the book to build your algorithm.\n",
    "\n",
    "In that case you don't really want to make a distinction between `apple` and `apples` or between `wheel` and `wheels`. You prefer to consider `apple` and `apples` as being variations of `apple`.\n",
    "\n",
    "To fix that, we will apply **lemmatization**. This approach aims to reduce each word to its simplest variation (named **lemma**). This lemma corresponds to the heading word in a language dictionary:\n",
    "\n",
    "\n",
    "**apple** (noun) : `a round fruit (usually with a green or red skin) which can be eaten (plural: apples)`\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## Still confused?\n",
    "Let's see how it works in a practical case.\n",
    "\n",
    "First, read [this article](https://www.machinelearningplus.com/nlp/lemmatization-examples-python/).\n",
    "\n",
    "Then, try to apply what you have learned by using SpaCy or NLTK.\n",
    "\n",
    "**Pro tips:** Most lemmatizers only work with a single word and not on sentences. Think about tokenizing your sentence first.\n",
    "\n",
    "**Pro tips:** If you experience SSL issues during `nltk` import [check this](https://stackoverflow.com/questions/38916452/nltk-download-ssl-certificate-verify-failed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you lemmatize this sentence with Spacy and / or NLTK?\n",
    "\n",
    "my_sentence = \"Those children are playing. this game, those games, I play he plays\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those child be play . this game , those game , I play he play\n"
     ]
    }
   ],
   "source": [
    "#Step 1 - Import Spacy\n",
    "import spacy\n",
    "\n",
    "#Step 2 - Initialize the Spacy en model.\n",
    "load_model = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Step 3 - Take a simple text for sample\n",
    "my_sentence = \"Those children are playing. this game, those games, I play he plays\"\n",
    "\n",
    "#Step 4 - Parse the text\n",
    "doc = load_model(my_sentence)\n",
    "\n",
    "#Step 5 - Extract the lemma for each token\n",
    "lemmatized_output = \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "print(lemmatized_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\yurit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yurit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yurit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child\n",
      "play\n",
      "playing\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Init the Wordnet Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatize Single Word\n",
    "print(lemmatizer.lemmatize(\"children\"))\n",
    "print(lemmatizer.lemmatize(\"plays\"))\n",
    "print(lemmatizer.lemmatize(\"playing\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Those', 'children', 'are', 'playing', '.', 'this', 'game', ',', 'those', 'games', ',', 'I', 'play', 'he', 'plays']\n",
      "Those child are playing . this game , those game , I play he play\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Define the sentence to be lemmatized\n",
    "sentence = \"Those children are playing. this game, those games, I play he plays\"\n",
    "\n",
    "# Tokenize: Split the sentence into words\n",
    "word_list = nltk.word_tokenize(sentence)\n",
    "print(word_list)\n",
    "\n",
    "# Lemmatize list of words and join\n",
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "print(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Those children are playing.', 'this game, those games, I play he plays']\n",
      "['Those', 'children', 'are', 'playing', '.', 'this', 'game', ',', 'those', 'games', ',', 'I', 'play', 'he', 'plays']\n",
      "Those child are playing . this game , those game , I play he play\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "my_sentence = \"Those children are playing. this game, those games, I play he plays\"\n",
    "\n",
    "#Tokenize: Split the sentence into words\n",
    "#word_list = nltk.sent_tokenize(my_sentence) # Tokenize sentences\n",
    "#print(word_list)\n",
    "\n",
    "# Tokenize: Split the sentence into words\n",
    "word_list = nltk.word_tokenize(my_sentence)\n",
    "print(word_list)\n",
    "\n",
    "# Lemmatize list of words and join\n",
    "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "print(lemmatized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{',': ',',\n",
      " '.': '.',\n",
      " 'I': 'I',\n",
      " 'Those': 'Those',\n",
      " 'are': 'are',\n",
      " 'child': 'children',\n",
      " 'game': 'games',\n",
      " 'he': 'he',\n",
      " 'play': 'plays',\n",
      " 'playing': 'playing',\n",
      " 'this': 'this',\n",
      " 'those': 'those'}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pprint import pprint\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmetize_print(words):\n",
    "     a = []\n",
    "     tokens = word_tokenize(words)\n",
    "     for token in tokens:\n",
    "          lemmetized_word = lemmatizer.lemmatize(token)\n",
    "          a.append(lemmetized_word)\n",
    "     pprint({a[i] : tokens[i] for i in range(len(a))}, indent = 1, depth=5)\n",
    "\n",
    "lemmetize_print(\"Those children are playing. this game, those games, I play he plays\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the differences between both tools ?\n",
    "yuri: spacy is an object-oriented whereas nltk is not\n",
    "## Conclusion\n",
    "There are multiple libraries that allow you to do lemmatization. Each of them have their particularities.\n",
    "There are also other techniques to \"simplify\" words like [Stemming](https://medium.com/swlh/introduction-to-stemming-vs-lemmatization-nlp-8c69eb43ecfe). Feel free explore those that seems relevant to your use-case.\n",
    "\n",
    "![stemming vs lemmatization](https://miro.medium.com/max/2050/1*ES5bt7IoInIq2YioQp2zcQ.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foot\n",
      "['Those', 'child', 'be', 'play', '.', 'this', 'game', ',', 'those', 'game', ',', 'I', 'play', 'he', 'play']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize with POS Tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "    \n",
    "# 1. Init Lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# 2. Lemmatize Single Word with the appropriate POS tag\n",
    "word = 'feet'\n",
    "print(lemmatizer.lemmatize(word, get_wordnet_pos(word)))\n",
    "\n",
    "# 3. Lemmatize a Sentence with the appropriate POS tag\n",
    "sentence = \"Those children are playing. this game, those games, I play he plays\"\n",
    "print([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('myNLTK')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e93389139a38db427026b9637522739d6fe06c48619f3fde42a7ea95a9cf1c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
